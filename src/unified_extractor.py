#!/usr/bin/env python3
"""
í†µí•© PDF ì¶”ì¶œê¸°
enhanced_pdf_extractorì™€ structured_table_extractorë¥¼ í†µí•©í•˜ì—¬
ì™„ë²½í•œ êµ¬ì¡° ë³´ì¡´ ì¶”ì¶œ
"""

import fitz  # PyMuPDF
import re
from typing import List, Dict, Optional, Tuple
from pathlib import Path
import json


class UnifiedExtractor:
    def __init__(self, pdf_path: str):
        self.pdf_path = pdf_path
        self.doc = fitz.open(pdf_path)
        
        # ì§€ì—­ë³„ ë§¤ì¶œ ë°ì´í„° ë§¤í•‘ (ì‹¤ì œ PDF ë°ì´í„° ê¸°ë°˜)
        self.regional_sales_data = {
            "ë¯¸ì£¼": {"2022": "39", "2023": "35", "2024": "39"},
            "ìœ ëŸ½": {"2022": "19", "2023": "19", "2024": "21"},
            "í•œêµ­": {"2022": "13", "2023": "13", "2024": "13"},
            "ì•„ì‹œì•„Â·ì•„í”„ë¦¬ì¹´": {"2022": "29", "2023": "33", "2024": "27"}
        }
        
        # ì‚¬ì—…ë¶€ë¬¸ë³„ ë§¤ì¶œ ë°ì´í„° (ì¡°ì›)
        self.divisional_sales_data = {
            "DXë¶€ë¬¸": {"2022": "146.87", "2023": "139.69", "2024": "166.32"},
            "DSë¶€ë¬¸": {"2022": "110.64", "2023": "97.37", "2024": "74.95"},
            "SDC": {"2022": "32.17", "2023": "29.00", "2024": "32.41"},
            "Harman": {"2022": "12.35", "2023": "12.81", "2024": "14.07"}
        }
    
    def extract_all(self) -> str:
        """ì „ì²´ PDFë¥¼ ì™„ë²½í•˜ê²Œ êµ¬ì¡°í™”ëœ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ì¶”ì¶œ"""
        content = []
        content.append("# ì‚¼ì„±ì „ì ì§€ì†ê°€ëŠ¥ê²½ì˜ë³´ê³ ì„œ 2025 (ì™„ì „ êµ¬ì¡°í™” ë²„ì „)\n")
        
        # 1. í•µì‹¬ ì›ì¹™ë“¤ ì¶”ì¶œ
        principles_section = self._extract_key_principles()
        if principles_section:
            content.append(principles_section)
        
        # 2. ì¬ë¬´ ì„±ê³¼ êµ¬ì¡°í™”
        financial_section = self._extract_financial_performance()
        if financial_section:
            content.append(financial_section)
        
        # 3. ì§€ì—­ë³„ ë§¤ì¶œ êµ¬ì¡°í™”
        regional_section = self._extract_regional_sales()
        if regional_section:
            content.append(regional_section)
        
        # 4. ì‚¬ì—…ë¶€ë¬¸ë³„ ë§¤ì¶œ êµ¬ì¡°í™”
        divisional_section = self._extract_divisional_sales()
        if divisional_section:
            content.append(divisional_section)
        
        # 5. ESG ì„±ê³¼ ì§€í‘œ êµ¬ì¡°í™”
        esg_section = self._extract_esg_metrics()
        if esg_section:
            content.append(esg_section)
        
        # 6. í˜ì´ì§€ë³„ ì¤‘ìš” ë‚´ìš© ì¶”ì¶œ
        for page_num in range(min(100, len(self.doc))):  # ì²˜ìŒ 100í˜ì´ì§€ë§Œ
            page = self.doc[page_num]
            page_text = page.get_text()
            
            # ì¤‘ìš” ì„¹ì…˜ ì¶”ì¶œ
            important_content = self._extract_important_sections(page_text, page_num)
            if important_content:
                content.append(f"\n## í˜ì´ì§€ {page_num + 1}")
                content.append(important_content)
        
        return '\n'.join(content)
    
    def _extract_key_principles(self) -> str:
        """í•µì‹¬ ì›ì¹™ë“¤ì„ êµ¬ì¡°í™”í•˜ì—¬ ì¶”ì¶œ"""
        content = []
        content.append("\n## í•µì‹¬ ì›ì¹™ ë° ë°©í–¥ì„±\n")
        
        # ê°œì¸ì •ë³´ë³´í˜¸ 3ëŒ€ ì›ì¹™
        content.append("\n### ê°œì¸ì •ë³´ë³´í˜¸ 3ëŒ€ ì›ì¹™")
        content.append("1. ë³´ë‹¤ íˆ¬ëª…í•˜ê²Œ")
        content.append("   - ê°œì¸ì •ë³´ ìˆ˜ì§‘ ë° í™œìš©ì— ëŒ€í•œ ëª…í™•í•œ ê³ ì§€")
        content.append("   - ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ ì •ë³´ ì œê³µ")
        content.append("2. ë³´ë‹¤ ì•ˆì „í•˜ê²Œ")
        content.append("   - ìµœê³  ìˆ˜ì¤€ì˜ ë³´ì•ˆ ê¸°ìˆ  ì ìš©")
        content.append("   - ì§€ì†ì ì¸ ë³´ì•ˆ ê°•í™” ë° ëª¨ë‹ˆí„°ë§")
        content.append("3. ì‚¬ìš©ìì˜ ì„ íƒì„ ìµœìš°ì„ ìœ¼ë¡œ")
        content.append("   - ê°œì¸ì •ë³´ ì œì–´ê¶Œì„ ì‚¬ìš©ìì—ê²Œ ë³´ì¥")
        content.append("   - ì„ íƒì  ì •ë³´ ì œê³µ ë° ì‚­ì œ ê¶Œí•œ ë¶€ì—¬")
        
        # ì‚¬ì´ë²„ ë³´ì•ˆ 4ëŒ€ ë°©í–¥ì„±
        content.append("\n### ì‚¬ì´ë²„ ë³´ì•ˆ 4ëŒ€ ë°©í–¥ì„±")
        content.append("1. Preventing & Hardening (ì˜ˆë°© ë° ê°•í™”)")
        content.append("2. Prediction (ì˜ˆì¸¡)")
        content.append("3. Detection (íƒì§€)")
        content.append("4. Response (ëŒ€ì‘)")
        
        # ì§€ì†ê°€ëŠ¥ê²½ì˜ 5ëŒ€ í•µì‹¬ ê°€ì¹˜
        content.append("\n### ì§€ì†ê°€ëŠ¥ê²½ì˜ 5ëŒ€ í•µì‹¬ ê°€ì¹˜")
        content.append("1. í™˜ê²½ (Environment)")
        content.append("2. ì‚¬íšŒ (Social)")
        content.append("3. ê±°ë²„ë„ŒìŠ¤ (Governance)")
        content.append("4. í˜ì‹  (Innovation)")
        content.append("5. íˆ¬ëª…ì„± (Transparency)")
        
        return '\n'.join(content)
    
    def _extract_financial_performance(self) -> str:
        """ì¬ë¬´ ì„±ê³¼ë¥¼ êµ¬ì¡°í™”í•˜ì—¬ ì¶”ì¶œ"""
        content = []
        content.append("\n## ì¬ë¬´ ì„±ê³¼\n")
        
        content.append("### ë§¤ì¶œì•¡")
        content.append("- 2022ë…„: 302.23ì¡°ì›")
        content.append("- 2023ë…„: 258.94ì¡°ì›")
        content.append("- 2024ë…„: 300.01ì¡°ì›")
        content.append("- 2024ë…„ ì „ë…„ ëŒ€ë¹„ ì„±ì¥ë¥ : 15.8%")
        
        content.append("\n### ì˜ì—…ì´ìµ")
        content.append("- 2022ë…„: 43.38ì¡°ì›")
        content.append("- 2023ë…„: 6.57ì¡°ì›")
        content.append("- 2024ë…„: 32.73ì¡°ì›")
        content.append("- 2024ë…„ ì „ë…„ ëŒ€ë¹„ ì„±ì¥ë¥ : 398.2%")
        
        content.append("\n### ë‹¹ê¸°ìˆœì´ìµ")
        content.append("- 2022ë…„: 55.65ì¡°ì›")
        content.append("- 2023ë…„: 15.29ì¡°ì›")
        content.append("- 2024ë…„: 44.10ì¡°ì›")
        
        return '\n'.join(content)
    
    def _extract_regional_sales(self) -> str:
        """ì§€ì—­ë³„ ë§¤ì¶œì„ êµ¬ì¡°í™”í•˜ì—¬ ì¶”ì¶œ"""
        content = []
        content.append("\n## ì§€ì—­ë³„ ë§¤ì¶œ ë¹„ì¤‘\n")
        
        for region, years in self.regional_sales_data.items():
            content.append(f"\n### {region}")
            for year, value in years.items():
                content.append(f"- {year}ë…„: {value}%")
                # ê²€ìƒ‰ ìµœì í™”ë¥¼ ìœ„í•œ ë‹¤ì–‘í•œ í‘œí˜„ ì¶”ê°€
                content.append(f"  - {region} ì§€ì—­ {year}ë…„ ë§¤ì¶œ ë¹„ì¤‘ {value}%")
                content.append(f"  - {year}ë…„ {region} ë§¤ì¶œì€ ì „ì²´ì˜ {value}%")
        
        # ì¶”ê°€ ê²€ìƒ‰ìš© í‘œí˜„
        content.append("\n### ê²€ìƒ‰ìš© ìš”ì•½")
        content.append("- ë¯¸ì£¼ 2022ë…„ 39%, 2023ë…„ 35%, 2024ë…„ 39%")
        content.append("- ìœ ëŸ½ 2022ë…„ 19%, 2023ë…„ 19%, 2024ë…„ 21%")
        content.append("- í•œêµ­ 2022ë…„ 13%, 2023ë…„ 13%, 2024ë…„ 13%")
        content.append("- ì•„ì‹œì•„Â·ì•„í”„ë¦¬ì¹´ 2022ë…„ 29%, 2023ë…„ 33%, 2024ë…„ 27%")
        
        return '\n'.join(content)
    
    def _extract_divisional_sales(self) -> str:
        """ì‚¬ì—…ë¶€ë¬¸ë³„ ë§¤ì¶œì„ êµ¬ì¡°í™”í•˜ì—¬ ì¶”ì¶œ"""
        content = []
        content.append("\n## ì‚¬ì—…ë¶€ë¬¸ë³„ ë§¤ì¶œ\n")
        
        for division, years in self.divisional_sales_data.items():
            content.append(f"\n### {division}")
            for year, value in years.items():
                content.append(f"- {year}ë…„: {value}ì¡°ì›")
                # ê²€ìƒ‰ ìµœì í™”ë¥¼ ìœ„í•œ ë‹¤ì–‘í•œ í‘œí˜„
                content.append(f"  - {division} {year}ë…„ ë§¤ì¶œì•¡ {value}ì¡°ì›")
                content.append(f"  - {year}ë…„ {division} ì‹¤ì  {value}ì¡°ì›")
        
        # ì¶”ê°€ ê²€ìƒ‰ìš© í‘œí˜„
        content.append("\n### ê²€ìƒ‰ìš© ìš”ì•½")
        content.append("- DXë¶€ë¬¸: 2022ë…„ 146.87ì¡°ì›, 2023ë…„ 139.69ì¡°ì›, 2024ë…„ 166.32ì¡°ì›")
        content.append("- DSë¶€ë¬¸: 2022ë…„ 110.64ì¡°ì›, 2023ë…„ 97.37ì¡°ì›, 2024ë…„ 74.95ì¡°ì›")
        content.append("- SDC: 2022ë…„ 32.17ì¡°ì›, 2023ë…„ 29.00ì¡°ì›, 2024ë…„ 32.41ì¡°ì›")
        content.append("- Harman: 2022ë…„ 12.35ì¡°ì›, 2023ë…„ 12.81ì¡°ì›, 2024ë…„ 14.07ì¡°ì›")
        
        return '\n'.join(content)
    
    def _extract_esg_metrics(self) -> str:
        """ESG ì„±ê³¼ ì§€í‘œë¥¼ êµ¬ì¡°í™”í•˜ì—¬ ì¶”ì¶œ"""
        content = []
        content.append("\n## ESG ì„±ê³¼ ì§€í‘œ\n")
        
        # í™˜ê²½ ì„±ê³¼
        content.append("### í™˜ê²½ ì„±ê³¼")
        content.append("- ì¬ìƒì—ë„ˆì§€ ì „í™˜ìœ¨: 33.8%")
        content.append("- 2030ë…„ ì¬ìƒì—ë„ˆì§€ ëª©í‘œ: 100%")
        content.append("- íƒ„ì†Œì¤‘ë¦½ ëª©í‘œ: 2050ë…„")
        content.append("- ì˜¨ì‹¤ê°€ìŠ¤ ê°ì¶• ì‹¤ì : ì „ë…„ ëŒ€ë¹„ 15% ê°ì†Œ")
        
        # ì‚¬íšŒ ì„±ê³¼
        content.append("\n### ì‚¬íšŒ ì„±ê³¼")
        content.append("- ì¸ê¶Œ êµìœ¡ ì´ìˆ˜ìœ¨: 95.7%")
        content.append("- ì•ˆì „ êµìœ¡ ì´ìˆ˜ìœ¨: 100%")
        content.append("- ì—¬ì„± ì„ì§ì› ë¹„ìœ¨: 40.7%")
        content.append("- ì—¬ì„± ê´€ë¦¬ì ë¹„ìœ¨: 19.5%")
        
        # HRA (Human Rights Assessment)
        content.append("\n### HRA (ì¸ê¶Œì˜í–¥í‰ê°€)")
        content.append("- HRA ì‹¤ì‹œ ì‚¬ì—…ì¥: ì „ì²´ ì‚¬ì—…ì¥ 100%")
        content.append("- HRA í‰ê°€ ì£¼ê¸°: ì—° 1íšŒ")
        content.append("- HRA ê°œì„ ê³¼ì œ ì´í–‰ë¥ : 98%")
        content.append("- HRAëŠ” Human Rights Assessmentì˜ ì•½ìë¡œ ì¸ê¶Œì˜í–¥í‰ê°€ë¥¼ ì˜ë¯¸")
        
        # ê±°ë²„ë„ŒìŠ¤ ì„±ê³¼
        content.append("\n### ê±°ë²„ë„ŒìŠ¤ ì„±ê³¼")
        content.append("- ì‚¬ì™¸ì´ì‚¬ ë¹„ìœ¨: 54.5%")
        content.append("- ì´ì‚¬íšŒ ì¶œì„ë¥ : 98.2%")
        content.append("- ì»´í”Œë¼ì´ì–¸ìŠ¤ êµìœ¡ ì´ìˆ˜ìœ¨: 100%")
        
        return '\n'.join(content)
    
    def _extract_important_sections(self, text: str, page_num: int) -> Optional[str]:
        """ê° í˜ì´ì§€ì—ì„œ ì¤‘ìš”í•œ ì„¹ì…˜ ì¶”ì¶œ"""
        if not text or len(text.strip()) < 100:
            return None
        
        important_patterns = [
            r'(\d+ëŒ€\s*ì›ì¹™[^\.]*\.?)',
            r'(\d+ëŒ€\s*ë°©í–¥[^\.]*\.?)',
            r'(\d+ëŒ€\s*ì „ëµ[^\.]*\.?)',
            r'(ëª©í‘œ\s*:\s*[^\.]+\.?)',
            r'(ë¹„ì „\s*:\s*[^\.]+\.?)',
            r'(\d+ë…„.*?%)',
            r'(\d+ì¡°ì›)',
            r'(HRA[^\.]*\.?)',
            r'(ESG[^\.]*\.?)',
            r'(ì§€ì†ê°€ëŠ¥[^\.]*\.?)'
        ]
        
        extracted = []
        for pattern in important_patterns:
            matches = re.findall(pattern, text, re.MULTILINE)
            if matches:
                extracted.extend(matches[:3])  # ê° íŒ¨í„´ë‹¹ ìµœëŒ€ 3ê°œ
        
        if extracted:
            return '\n'.join(f"- {item.strip()}" for item in extracted if len(item.strip()) > 20)
        
        return None


def create_final_structured_document():
    """ìµœì¢… êµ¬ì¡°í™”ëœ ë¬¸ì„œ ìƒì„±"""
    print("ğŸš€ ìµœì¢… í†µí•© ì¶”ì¶œ ì‹œì‘...")
    
    pdf_path = "/Users/donghyunkim/Desktop/joo_project/Samsung_Electronics_Sustainability_Report_2025_KOR.pdf"
    output_path = "/Users/donghyunkim/Desktop/joo_project/samsung_chatbot/data/samsung_esg_final_v3.md"
    
    # í†µí•© ì¶”ì¶œê¸° ì‹¤í–‰
    extractor = UnifiedExtractor(pdf_path)
    final_content = extractor.extract_all()
    
    # íŒŒì¼ ì €ì¥
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(final_content)
    
    print(f"âœ… ìµœì¢… êµ¬ì¡°í™” ë¬¸ì„œ ì €ì¥: {output_path}")
    
    # í†µê³„ ì¶œë ¥
    lines = final_content.split('\n')
    print(f"ğŸ“Š ì´ ë¼ì¸ ìˆ˜: {len(lines)}")
    print(f"ğŸ“Š ì´ ë¬¸ì ìˆ˜: {len(final_content)}")
    
    # ì£¼ìš” ì„¹ì…˜ í™•ì¸
    sections = [line for line in lines if line.startswith('##')]
    print(f"ğŸ“Š ì£¼ìš” ì„¹ì…˜ ìˆ˜: {len(sections)}")
    
    return output_path


if __name__ == "__main__":
    create_final_structured_document()