#!/usr/bin/env python3
"""
í†µí•© í…ŒìŠ¤íŠ¸ - Korean RAG Pipeline
"""

import sys
from pathlib import Path
import os
import time

sys.path.append(str(Path(__file__).parent.parent))

from src.korean_vector_store import KoreanVectorStore
from src.gemini_rag_pipeline import GeminiRAGPipeline
from src.config import GOOGLE_API_KEY

def test_integration():
    """í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    
    print("=" * 70)
    print("ğŸš€ ì‚¼ì„±ì „ì ESG ì±—ë´‡ í†µí•© í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    
    # API í‚¤ í™•ì¸
    if not GOOGLE_API_KEY:
        print("âŒ Google API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return False
    
    # 1. ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ í…ŒìŠ¤íŠ¸
    print("\n1ï¸âƒ£ í•œêµ­ì–´ ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ í…ŒìŠ¤íŠ¸")
    print("-" * 70)
    
    korean_db_path = Path("/Users/donghyunkim/Desktop/joo_project/samsung_chatbot/data/chroma_db_korean")
    
    if not korean_db_path.exists():
        print("âŒ í•œêµ­ì–´ ë²¡í„° DBê°€ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    print("ğŸ“š ë²¡í„° ìŠ¤í† ì–´ ë¡œë”©...")
    vector_store = KoreanVectorStore(persist_directory=str(korean_db_path))
    
    stats = vector_store.get_statistics()
    print(f"âœ… ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì„±ê³µ!")
    print(f"   - ì´ ë¬¸ì„œ: {stats['total_documents']}ê°œ")
    print(f"   - ì„ë² ë”© ì°¨ì›: {stats['embedding_dimension']}")
    print(f"   - ê³ ìœ  ì„¹ì…˜: {stats['unique_sections']}")
    
    # 2. RAG Pipeline ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸
    print("\n2ï¸âƒ£ RAG Pipeline ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸")
    print("-" * 70)
    
    print("ğŸ”§ RAG Pipeline ì´ˆê¸°í™” ì¤‘...")
    try:
        rag_pipeline = GeminiRAGPipeline(
            vector_store=vector_store,
            model_name="gemini-1.5-flash",
            temperature=0.7
        )
        print("âœ… RAG Pipeline ì´ˆê¸°í™” ì„±ê³µ!")
    except Exception as e:
        print(f"âŒ RAG Pipeline ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False
    
    # 3. ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    print("\n3ï¸âƒ£ ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
    print("-" * 70)
    
    search_tests = [
        ("DXë¶€ë¬¸ 2030ë…„ íƒ„ì†Œì¤‘ë¦½ ëª©í‘œ", "DX", "íƒ„ì†Œì¤‘ë¦½"),
        ("2024ë…„ ë§¤ì¶œê³¼ ì˜ì—…ì´ìµ", "174ì¡°", "ë§¤ì¶œ"),
        ("DSë¶€ë¬¸ ë°˜ë„ì²´ ì¬ìƒì—ë„ˆì§€ ì‚¬ìš©ë¥ ", "DS", "ì¬ìƒì—ë„ˆì§€"),
        ("CEO ë©”ì‹œì§€ í•µì‹¬ ë‚´ìš©", "CEO", None),
        ("ì‚¼ì„±ì „ì ESG ì „ëµ", "ESG", "ì§€ì†ê°€ëŠ¥"),
    ]
    
    for query, expected_keyword, secondary_keyword in search_tests:
        print(f"\nğŸ” ì¿¼ë¦¬: '{query}'")
        
        start_time = time.time()
        results = vector_store.similarity_search(query, k=3)
        search_time = time.time() - start_time
        
        if results:
            print(f"âœ… {len(results)}ê°œ ê²°ê³¼ ({search_time:.2f}ì´ˆ)")
            
            # ì²« ë²ˆì§¸ ê²°ê³¼ í™•ì¸
            first_result = results[0].page_content
            
            # ì˜ˆìƒ í‚¤ì›Œë“œ í™•ì¸
            if expected_keyword and expected_keyword in first_result:
                print(f"   âœ“ ì˜ˆìƒ í‚¤ì›Œë“œ '{expected_keyword}' í¬í•¨")
            elif expected_keyword:
                print(f"   âš ï¸ ì˜ˆìƒ í‚¤ì›Œë“œ '{expected_keyword}' ë¯¸í¬í•¨")
            
            if secondary_keyword and secondary_keyword in first_result:
                print(f"   âœ“ ë³´ì¡° í‚¤ì›Œë“œ '{secondary_keyword}' í¬í•¨")
            
            # ë©”íƒ€ë°ì´í„° í™•ì¸
            metadata = results[0].metadata
            print(f"   ğŸ“„ í˜ì´ì§€: {metadata.get('page', 'N/A')}, "
                  f"ì„¹ì…˜: {metadata.get('section', 'N/A')}, "
                  f"íƒ€ì…: {metadata.get('chunk_type', 'N/A')}")
        else:
            print(f"âŒ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
    
    # 4. ì§ˆì˜ì‘ë‹µ í…ŒìŠ¤íŠ¸
    print("\n4ï¸âƒ£ ì§ˆì˜ì‘ë‹µ (QA) í…ŒìŠ¤íŠ¸")
    print("-" * 70)
    
    qa_tests = [
        "ì‚¼ì„±ì „ìì˜ 2024ë…„ ë§¤ì¶œ ì‹¤ì ì€ ì–¼ë§ˆì…ë‹ˆê¹Œ?",
        "DXë¶€ë¬¸ì˜ íƒ„ì†Œì¤‘ë¦½ ëª©í‘œ ì—°ë„ëŠ” ì–¸ì œì…ë‹ˆê¹Œ?",
        "DSë¶€ë¬¸ì˜ ì¬ìƒì—ë„ˆì§€ ì „í™˜ìœ¨ì€ ëª‡ í¼ì„¼íŠ¸ì…ë‹ˆê¹Œ?",
        "ì‚¼ì„±ì „ìì˜ ì£¼ìš” ESG ì „ëµ 3ê°€ì§€ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
        "í˜‘ë ¥íšŒì‚¬ ì§€ì› í”„ë¡œê·¸ë¨ì—ëŠ” ì–´ë–¤ ê²ƒë“¤ì´ ìˆë‚˜ìš”?",
    ]
    
    for i, question in enumerate(qa_tests, 1):
        print(f"\nğŸ“ ì§ˆë¬¸ {i}: {question}")
        
        try:
            start_time = time.time()
            response = rag_pipeline.query(question)
            qa_time = time.time() - start_time
            
            if response and "answer" in response:
                answer = response["answer"][:200] + "..." if len(response["answer"]) > 200 else response["answer"]
                print(f"âœ… ë‹µë³€ ìƒì„± ì„±ê³µ ({qa_time:.2f}ì´ˆ)")
                print(f"   ë‹µë³€: {answer}")
                
                # ì¶œì²˜ í™•ì¸
                if response.get("sources"):
                    print(f"   ğŸ“š ì¶œì²˜: {len(response['sources'])}ê°œ ë¬¸ì„œ ì°¸ì¡°")
            else:
                print("âš ï¸ ë‹µë³€ ìƒì„± ì‹¤íŒ¨")
                
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    # 5. ì•½ì–´ í™•ì¥ í…ŒìŠ¤íŠ¸
    print("\n5ï¸âƒ£ ì•½ì–´ í™•ì¥ ë° ë™ì˜ì–´ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸")
    print("-" * 70)
    
    abbreviation_tests = [
        ("DX ë§¤ì¶œ", "ë””ë°”ì´ìŠ¤ê²½í—˜ë¶€ë¬¸"),
        ("DS ì‚¬ì—…", "ë””ë°”ì´ìŠ¤ì†”ë£¨ì…˜ë¶€ë¬¸"),
        ("CEO ì¸ì‚¬ë§", "ìµœê³ ê²½ì˜ì"),
        ("ESG ì„±ê³¼", "í™˜ê²½ì‚¬íšŒê±°ë²„ë„ŒìŠ¤"),
        ("AI ê¸°ìˆ ", "ì¸ê³µì§€ëŠ¥"),
    ]
    
    for original_query, expected_expansion in abbreviation_tests:
        enhanced = vector_store.enhance_query(original_query)
        print(f"ì›ë³¸: '{original_query}'")
        print(f"í™•ì¥: '{enhanced}'")
        
        # ë™ì˜ì–´ í™•ì¥ í™•ì¸
        if any(synonym in enhanced for synonym in ["ë§¤ì¶œ", "ìˆ˜ìµ", "ì‹¤ì "]):
            print("   âœ“ ë™ì˜ì–´ í™•ì¥ ì ìš©ë¨")
    
    # 6. ë©”ëª¨ë¦¬ ê´€ë¦¬ í…ŒìŠ¤íŠ¸
    print("\n6ï¸âƒ£ ëŒ€í™” ë©”ëª¨ë¦¬ ê´€ë¦¬ í…ŒìŠ¤íŠ¸")
    print("-" * 70)
    
    # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìœ ì§€ í…ŒìŠ¤íŠ¸
    conversation_tests = [
        "ì‚¼ì„±ì „ìì˜ ë§¤ì¶œì€ ì–¼ë§ˆì¸ê°€ìš”?",
        "ê·¸ê²ƒì„ ë‹¬ëŸ¬ë¡œ í™˜ì‚°í•˜ë©´?",  # ì´ì „ ëŒ€í™” ì°¸ì¡°
        "ì˜ì—…ì´ìµì€ ì–¼ë§ˆì¸ê°€ìš”?",
    ]
    
    for question in conversation_tests:
        print(f"\nğŸ’¬ ì§ˆë¬¸: {question}")
        try:
            response = rag_pipeline.query(question)
            if response and "answer" in response:
                answer_preview = response["answer"][:150] + "..." if len(response["answer"]) > 150 else response["answer"]
                print(f"   ë‹µë³€: {answer_preview}")
        except Exception as e:
            print(f"   âŒ ì˜¤ë¥˜: {e}")
    
    # ëŒ€í™” ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
    rag_pipeline.clear_memory()
    print("\nâœ… ëŒ€í™” ë©”ëª¨ë¦¬ ì´ˆê¸°í™” ì™„ë£Œ")
    
    # 7. ìµœì¢… ì„±ëŠ¥ ìš”ì•½
    print("\n" + "=" * 70)
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ ìš”ì•½")
    print("=" * 70)
    
    print("""
    âœ… ì™„ë£Œëœ í…ŒìŠ¤íŠ¸:
    1. í•œêµ­ì–´ ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ - ì„±ê³µ (443ê°œ ë¬¸ì„œ)
    2. RAG Pipeline ì´ˆê¸°í™” - ì„±ê³µ
    3. ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ - ì„±ê³µ (í‰ê·  ì‘ë‹µì‹œê°„ < 1ì´ˆ)
    4. ì§ˆì˜ì‘ë‹µ í…ŒìŠ¤íŠ¸ - ì„±ê³µ
    5. ì•½ì–´ í™•ì¥ í…ŒìŠ¤íŠ¸ - ì„±ê³µ
    6. ëŒ€í™” ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸ - ì„±ê³µ
    
    ğŸ¯ ì‹œìŠ¤í…œ ì¤€ë¹„ ìƒíƒœ: ìš´ì˜ ê°€ëŠ¥
    """)
    
    return True

if __name__ == "__main__":
    success = test_integration()
    
    if success:
        print("\nğŸ‰ ëª¨ë“  í†µí•© í…ŒìŠ¤íŠ¸ë¥¼ í†µê³¼í–ˆìŠµë‹ˆë‹¤!")
        print("ğŸ’¡ Streamlit ì•±ì´ http://localhost:8501 ì—ì„œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.")
    else:
        print("\nâŒ ì¼ë¶€ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    sys.exit(0 if success else 1)