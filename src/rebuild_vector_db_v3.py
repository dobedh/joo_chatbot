#!/usr/bin/env python3
"""
ë²¡í„° DB v3 ì¬êµ¬ì¶•
ì™„ë²½í•˜ê²Œ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë²¡í„° DB ì¬ìƒì„±
"""

import os
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.korean_vector_store import KoreanVectorStore
from src.smart_chunker import SmartChunker
import chromadb
from chromadb.config import Settings
import shutil


def rebuild_vector_database_v3():
    """ê°œì„ ëœ ë°ì´í„°ë¡œ ë²¡í„° DB v3 ì¬êµ¬ì¶•"""
    
    print("ğŸš€ ë²¡í„° DB v3 ì¬êµ¬ì¶• ì‹œì‘...")
    
    # 1. ê¸°ì¡´ DB ì‚­ì œ
    chroma_path = project_root / "data" / "chroma_db"
    if chroma_path.exists():
        print("ğŸ—‘ï¸ ê¸°ì¡´ ë²¡í„° DB ì‚­ì œ ì¤‘...")
        shutil.rmtree(chroma_path)
    
    # 2. ìƒˆ ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”
    print("ğŸ“¦ ìƒˆ ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”...")
    vector_store = KoreanVectorStore(
        persist_directory=str(chroma_path)
    )
    
    # 3. ìŠ¤ë§ˆíŠ¸ ì²­ì»¤ ì´ˆê¸°í™” (ìµœì í™”ëœ íŒŒë¼ë¯¸í„°)
    print("âœ‚ï¸ ìŠ¤ë§ˆíŠ¸ ì²­ì»¤ ì´ˆê¸°í™”...")
    chunker = SmartChunker(
        chunk_size=1200,  # ìµœì í™”ëœ í¬ê¸°
        chunk_overlap=300  # ì¶©ë¶„í•œ ì˜¤ë²„ë©
    )
    
    # 4. êµ¬ì¡°í™”ëœ ë¬¸ì„œ ë¡œë“œ
    structured_file = project_root / "data" / "samsung_esg_final_v3.md"
    
    if not structured_file.exists():
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {structured_file}")
        return
    
    print(f"ğŸ“„ êµ¬ì¡°í™”ëœ ë¬¸ì„œ ë¡œë“œ: {structured_file}")
    
    # 5. ì²­í‚¹ ìˆ˜í–‰
    print("âœ‚ï¸ ë¬¸ì„œ ì²­í‚¹ ì¤‘...")
    chunks = chunker.chunk_markdown(structured_file)
    print(f"âœ… {len(chunks)} ê°œ ì²­í¬ ìƒì„±")
    
    # 6. ì²­í¬ í’ˆì§ˆ ê²€ì¦
    print("\nğŸ“Š ì²­í¬ í’ˆì§ˆ ê²€ì¦:")
    
    # ì£¼ìš” í‚¤ì›Œë“œ ê²€ì¦
    key_terms = [
        "ê°œì¸ì •ë³´ë³´í˜¸ 3ëŒ€ ì›ì¹™",
        "ë¯¸ì£¼ 2022ë…„ 39%",
        "DXë¶€ë¬¸",
        "HRA",
        "ì¸ê¶Œ êµìœ¡",
        "95.7%",
        "ì¬ìƒì—ë„ˆì§€",
        "ESG"
    ]
    
    for term in key_terms:
        found_chunks = [i for i, chunk in enumerate(chunks) if term in chunk['content']]
        if found_chunks:
            print(f"  âœ… '{term}' ë°œê²¬: {len(found_chunks)}ê°œ ì²­í¬")
        else:
            print(f"  âš ï¸ '{term}' ë¯¸ë°œê²¬")
    
    # 7. ë²¡í„° DBì— ì¶”ê°€
    print("\nğŸ’¾ ë²¡í„° DBì— ì²­í¬ ì¶”ê°€ ì¤‘...")
    # chunksì—ì„œ textsì™€ metadatas ë¶„ë¦¬
    texts = [chunk['content'] for chunk in chunks]
    metadatas = []
    for chunk in chunks:
        # ë©”íƒ€ë°ì´í„°ì—ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        metadata = {}
        for key, value in chunk['metadata'].items():
            if isinstance(value, list):
                metadata[key] = ', '.join(str(v) for v in value)
            else:
                metadata[key] = value
        metadatas.append(metadata)
    vector_store.add_documents(texts, metadatas)
    
    # 8. í†µê³„ ì¶œë ¥
    print("\nğŸ“Š ë²¡í„° DB v3 êµ¬ì¶• ì™„ë£Œ:")
    print(f"  - ì´ ì²­í¬ ìˆ˜: {len(chunks)}")
    print(f"  - í‰ê·  ì²­í¬ ê¸¸ì´: {sum(len(c['content']) for c in chunks) / len(chunks):.0f}ì")
    print(f"  - ìµœì†Œ ì²­í¬ ê¸¸ì´: {min(len(c['content']) for c in chunks)}ì")
    print(f"  - ìµœëŒ€ ì²­í¬ ê¸¸ì´: {max(len(c['content']) for c in chunks)}ì")
    
    # 9. í…ŒìŠ¤íŠ¸ ê²€ìƒ‰
    print("\nğŸ” í…ŒìŠ¤íŠ¸ ê²€ìƒ‰ ìˆ˜í–‰:")
    test_queries = [
        "ê°œì¸ì •ë³´ë³´í˜¸ 3ëŒ€ ì›ì¹™ì´ ë­ì•¼?",
        "ë¯¸ì£¼ 2022ë…„ ë§¤ì¶œ ë¹„ì¤‘ì€?",
        "HRAê°€ ë­ì•¼?",
        "ì¸ê¶Œ êµìœ¡ì„ ëª‡í”„ë¡œê°€ ë°›ì•˜ì–´?",
        "DXë¶€ë¬¸ 2024ë…„ ë§¤ì¶œì€?"
    ]
    
    for query in test_queries:
        results = vector_store.similarity_search(query, k=3)
        if results:
            print(f"\n  Q: {query}")
            print(f"  A: {results[0].page_content[:100]}...")
            # ì •ë‹µ í¬í•¨ ì—¬ë¶€ ì²´í¬
            if "ê°œì¸ì •ë³´ë³´í˜¸" in query and "íˆ¬ëª…í•˜ê²Œ" in results[0].page_content:
                print("  âœ… ì •ë‹µ í¬í•¨")
            elif "ë¯¸ì£¼" in query and "39" in results[0].page_content:
                print("  âœ… ì •ë‹µ í¬í•¨")
            elif "HRA" in query and ("Human Rights" in results[0].page_content or "ì¸ê¶Œ" in results[0].page_content):
                print("  âœ… ì •ë‹µ í¬í•¨")
            elif "ì¸ê¶Œ êµìœ¡" in query and "95.7" in results[0].page_content:
                print("  âœ… ì •ë‹µ í¬í•¨")
            elif "DXë¶€ë¬¸" in query and "166.32" in results[0].page_content:
                print("  âœ… ì •ë‹µ í¬í•¨")
        else:
            print(f"\n  Q: {query}")
            print(f"  A: ê²°ê³¼ ì—†ìŒ âŒ")
    
    print("\nâœ… ë²¡í„° DB v3 ì¬êµ¬ì¶• ì™„ë£Œ!")
    print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {chroma_path}")
    
    return vector_store


if __name__ == "__main__":
    rebuild_vector_database_v3()