#!/usr/bin/env python3
"""
PyMuPDFì™€ Geminië¥¼ ì‚¬ìš©í•œ ê³ ê¸‰ PDF ì¶”ì¶œê¸°
í‘œì™€ í…ìŠ¤íŠ¸ë¥¼ ì •í™•í•˜ê²Œ ì¶”ì¶œí•˜ê³  ì •ì œ
"""

import fitz  # PyMuPDF
from pathlib import Path
import re
import json
from typing import List, Dict, Optional
import google.generativeai as genai
import os
from dotenv import load_dotenv

load_dotenv()

class AdvancedPDFExtractor:
    def __init__(self, pdf_path: Path):
        self.pdf_path = pdf_path
        self.doc = None
        self.extracted_content = []
        
        # Gemini ì„¤ì •
        genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
        self.model = genai.GenerativeModel('gemini-1.5-flash')
        
    def extract(self) -> List[Dict]:
        """PDF ì „ì²´ ì¶”ì¶œ"""
        print(f"ğŸ“š ê³ ê¸‰ PDF ì¶”ì¶œ ì‹œì‘: {self.pdf_path}")
        
        self.doc = fitz.open(self.pdf_path)
        total_pages = len(self.doc)
        
        for page_num in range(total_pages):
            print(f"ì²˜ë¦¬ ì¤‘: í˜ì´ì§€ {page_num + 1}/{total_pages}")
            page = self.doc[page_num]
            
            page_content = self._extract_page(page, page_num + 1)
            if page_content:
                self.extracted_content.append(page_content)
        
        self.doc.close()
        return self.extracted_content
    
    def _extract_page(self, page, page_num: int) -> Dict:
        """ê° í˜ì´ì§€ ì¶”ì¶œ ë° êµ¬ì¡°í™”"""
        page_data = {
            'page': page_num,
            'text': '',
            'tables': [],
            'structured_content': ''
        }
        
        # 1. í…ìŠ¤íŠ¸ ì¶”ì¶œ
        text = page.get_text()
        page_data['text'] = self._clean_text(text)
        
        # 2. í‘œ ì¶”ì¶œ ì‹œë„
        tables = self._extract_tables_from_page(page)
        if tables:
            page_data['tables'] = tables
        
        # 3. êµ¬ì¡°í™”ëœ ì»¨í…ì¸  ìƒì„±
        page_data['structured_content'] = self._create_structured_content(
            page_data['text'], 
            page_data['tables'],
            page_num
        )
        
        return page_data
    
    def _extract_tables_from_page(self, page) -> List[Dict]:
        """í˜ì´ì§€ì—ì„œ í‘œ ì¶”ì¶œ"""
        tables = []
        
        # PyMuPDFì˜ í‘œ ê°ì§€ ê¸°ëŠ¥ ì‚¬ìš©
        try:
            # í…ìŠ¤íŠ¸ ë¸”ë¡ ë¶„ì„
            blocks = page.get_text("dict")
            
            # í…Œì´ë¸” íŒ¨í„´ ê°ì§€ (ìˆ«ìì™€ êµ¬ë¶„ìê°€ ë§ì€ ì˜ì—­)
            potential_tables = self._detect_table_regions(blocks)
            
            for table_region in potential_tables:
                table_data = self._parse_table_region(table_region)
                if table_data:
                    tables.append(table_data)
        except Exception as e:
            print(f"í‘œ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        
        return tables
    
    def _detect_table_regions(self, blocks) -> List:
        """í‘œ ì˜ì—­ ê°ì§€"""
        table_regions = []
        
        for block in blocks.get('blocks', []):
            if block.get('type') == 0:  # í…ìŠ¤íŠ¸ ë¸”ë¡
                lines = block.get('lines', [])
                
                # ìˆ«ìê°€ ë§ê³  ì •ë ¬ëœ íŒ¨í„´ ì°¾ê¸°
                numeric_lines = 0
                for line in lines:
                    text = ''.join([span['text'] for span in line.get('spans', [])])
                    # ìˆ«ì, ì½¤ë§ˆ, ì¡°, ì–µ, ì› ë“±ì´ í¬í•¨ëœ ë¼ì¸
                    if re.search(r'\d+[,\d]*\s*(ì¡°|ì–µ|ì›|%|ê°œ)', text):
                        numeric_lines += 1
                
                # ìˆ«ìê°€ ë§ì€ ë¸”ë¡ì€ í‘œì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒ
                if numeric_lines >= 2:
                    table_regions.append(block)
        
        return table_regions
    
    def _parse_table_region(self, region) -> Optional[Dict]:
        """í‘œ ì˜ì—­ íŒŒì‹±"""
        lines = []
        for line in region.get('lines', []):
            text = ''.join([span['text'] for span in line.get('spans', [])])
            lines.append(text.strip())
        
        if not lines:
            return None
        
        # í‘œë¥¼ êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        table_text = '\n'.join(lines)
        
        # íŠ¹ì • íŒ¨í„´ ì¸ì‹ (ì˜ˆ: ë§¤ì¶œ, ì˜ì—…ì´ìµ ë“±)
        if any(keyword in table_text for keyword in ['ë§¤ì¶œ', 'ì˜ì—…ì´ìµ', 'ìì‚°', 'ë¶€ì±„']):
            return {
                'type': 'financial',
                'content': table_text,
                'parsed': self._parse_financial_table(table_text)
            }
        
        return {
            'type': 'general',
            'content': table_text
        }
    
    def _parse_financial_table(self, table_text: str) -> Dict:
        """ì¬ë¬´ í‘œ íŒŒì‹±"""
        parsed = {}
        
        # íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ì£¼ìš” ìˆ˜ì¹˜ ì¶”ì¶œ
        patterns = [
            (r'DX.*?(\d+[\d,]*)\s*(ì¡°|ì–µ)', 'DX_ë§¤ì¶œ'),
            (r'DS.*?(\d+[\d,]*)\s*(ì¡°|ì–µ)', 'DS_ë§¤ì¶œ'),
            (r'ë§¤ì¶œ.*?(\d+[\d,]*)\s*(ì¡°|ì–µ)', 'ì´ë§¤ì¶œ'),
            (r'ì˜ì—…ì´ìµ.*?(\d+[\d,]*)\s*(ì¡°|ì–µ)', 'ì˜ì—…ì´ìµ'),
        ]
        
        for pattern, key in patterns:
            match = re.search(pattern, table_text)
            if match:
                value = match.group(1).replace(',', '')
                unit = match.group(2)
                parsed[key] = f"{value}{unit}"
        
        return parsed
    
    def _clean_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì •ì œ"""
        # ì¤‘ë³µ ë¬¸ì ì œê±°
        text = re.sub(r'([A-Z])\1+', r'\1', text)  # AA -> A
        text = re.sub(r'([a-z])\1{2,}', r'\1', text)  # aaa -> a
        
        # íŠ¹ì • íŒ¨í„´ ìˆ˜ì •
        replacements = [
            (r'AA JJoouurrnneeyy TT oowwaarrddss', 'A Journey Towards'),
            (r'aa SSuussttaa?ii?nnaabbllee FFuuttuurree', 'a Sustainable Future'),
            (r'([ê°€-í£])\1+', r'\1'),  # í•œê¸€ ì¤‘ë³µ ì œê±°
        ]
        
        for pattern, replacement in replacements:
            text = re.sub(pattern, replacement, text)
        
        # ë¶ˆí•„ìš”í•œ ê³µë°± ì •ë¦¬
        text = re.sub(r'\s+', ' ', text)
        text = re.sub(r'\n{3,}', '\n\n', text)
        
        return text.strip()
    
    def _create_structured_content(self, text: str, tables: List[Dict], page_num: int) -> str:
        """êµ¬ì¡°í™”ëœ ì½˜í…ì¸  ìƒì„±"""
        content = [f"## í˜ì´ì§€ {page_num}\n"]
        
        # ì£¼ìš” ì œëª© ì¶”ì¶œ
        lines = text.split('\n')
        for line in lines[:5]:  # ì²˜ìŒ 5ì¤„ì—ì„œ ì œëª© ì°¾ê¸°
            if len(line) > 10 and len(line) < 100:
                if any(keyword in line for keyword in ['CEO', 'ë©”ì‹œì§€', 'ê°œìš”', 'ì„±ê³¼', 'ëª©í‘œ']):
                    content.append(f"### {line.strip()}\n")
                    break
        
        # í‘œ ë°ì´í„°ë¥¼ êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        if tables:
            content.append("\n### ğŸ“Š ì£¼ìš” ë°ì´í„°\n")
            for table in tables:
                if table['type'] == 'financial' and table.get('parsed'):
                    content.append("\n**ì¬ë¬´ ì„±ê³¼:**\n")
                    for key, value in table['parsed'].items():
                        clean_key = key.replace('_', ' ')
                        content.append(f"- {clean_key}: {value}\n")
                else:
                    content.append(f"\n```\n{table['content']}\n```\n")
        
        # ë³¸ë¬¸ í…ìŠ¤íŠ¸ ì¶”ê°€
        content.append("\n### ë³¸ë¬¸\n")
        
        # ê¸´ í…ìŠ¤íŠ¸ë¥¼ ë¬¸ë‹¨ìœ¼ë¡œ ë¶„ë¦¬
        paragraphs = self._split_into_paragraphs(text)
        for para in paragraphs:
            if len(para) > 50:  # ì˜ë¯¸ ìˆëŠ” ê¸¸ì´ì˜ ë¬¸ë‹¨ë§Œ
                content.append(f"\n{para}\n")
        
        return ''.join(content)
    
    def _split_into_paragraphs(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ë¬¸ë‹¨ìœ¼ë¡œ ë¶„ë¦¬"""
        # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
        sentences = re.split(r'[.!?]\s+', text)
        
        paragraphs = []
        current_para = []
        
        for sentence in sentences:
            current_para.append(sentence)
            
            # 3-5 ë¬¸ì¥ë§ˆë‹¤ ë¬¸ë‹¨ êµ¬ë¶„
            if len(current_para) >= 3:
                para_text = '. '.join(current_para) + '.'
                if len(para_text) > 100:
                    paragraphs.append(para_text)
                    current_para = []
        
        # ë‚¨ì€ ë¬¸ì¥ ì²˜ë¦¬
        if current_para:
            paragraphs.append('. '.join(current_para) + '.')
        
        return paragraphs
    
    def refine_with_llm(self, content: str) -> str:
        """Geminië¥¼ ì‚¬ìš©í•´ í…ìŠ¤íŠ¸ ì •ì œ"""
        prompt = f"""
        ë‹¤ìŒ í…ìŠ¤íŠ¸ëŠ” PDFì—ì„œ ì¶”ì¶œëœ ê²ƒì…ë‹ˆë‹¤. ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:
        
        1. ì¤‘ë³µëœ ë¬¸ì ìˆ˜ì • (ì˜ˆ: AA JJoouurrnneeyy â†’ A Journey)
        2. ë¶„ë¦¬ëœ ìˆ«ìì™€ ë‹¨ìœ„ ê²°í•© (ì˜ˆ: 174 ì¡° 8,877 ì–µ ì› â†’ 174ì¡° 8,877ì–µì›)
        3. í‘œ ë°ì´í„°ë¥¼ êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        4. ë¬¸ë§¥ìƒ ì˜ë¯¸ê°€ í†µí•˜ë„ë¡ ë¬¸ì¥ ì •ë¦¬
        
        ì›ë³¸ í…ìŠ¤íŠ¸:
        {content[:2000]}  # API í•œê³„ë¡œ ì¼ë¶€ë§Œ ì „ì†¡
        
        ì •ì œëœ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥í•˜ì„¸ìš”:
        """
        
        try:
            response = self.model.generate_content(prompt)
            return response.text
        except Exception as e:
            print(f"LLM ì •ì œ ì˜¤ë¥˜: {e}")
            return content
    
    def save_as_markdown(self, output_path: Path):
        """ë§ˆí¬ë‹¤ìš´ íŒŒì¼ë¡œ ì €ì¥"""
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write("# ì‚¼ì„±ì „ì ì§€ì†ê°€ëŠ¥ê²½ì˜ ë³´ê³ ì„œ 2025\n")
            f.write("*PyMuPDFì™€ Geminië¡œ ì¶”ì¶œ ë° ì •ì œ*\n\n")
            f.write("---\n\n")
            
            for page_data in self.extracted_content:
                f.write(page_data['structured_content'])
                f.write("\n\n---\n\n")
        
        print(f"âœ… ì €ì¥ ì™„ë£Œ: {output_path}")


def main():
    pdf_path = Path("/Users/donghyunkim/Desktop/joo_project/Samsung_Electronics_Sustainability_Report_2025_KOR.pdf")
    output_path = Path("/Users/donghyunkim/Desktop/joo_project/samsung_chatbot/data/samsung_esg_advanced.md")
    
    # ì¶”ì¶œê¸° ìƒì„±
    extractor = AdvancedPDFExtractor(pdf_path)
    
    # PDF ì¶”ì¶œ
    content = extractor.extract()
    
    # ë§ˆí¬ë‹¤ìš´ ì €ì¥
    extractor.save_as_markdown(output_path)
    
    # ìƒ˜í”Œ LLM ì •ì œ (ì²˜ìŒ 3í˜ì´ì§€ë§Œ)
    print("\nğŸ¤– Geminië¡œ í…ìŠ¤íŠ¸ ì •ì œ ì¤‘...")
    for i in range(min(3, len(content))):
        refined = extractor.refine_with_llm(content[i]['text'])
        print(f"\ní˜ì´ì§€ {i+1} ì •ì œ ê²°ê³¼ (ì¼ë¶€):")
        print(refined[:300] + "...")
    
    return output_path


if __name__ == "__main__":
    output = main()
    print(f"\nâœ… ì™„ë£Œ! ë‹¤ìŒ íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”: {output}")