#!/usr/bin/env python3
"""
RAG ì‹œìŠ¤í…œ ë¹„ìš© ê³„ì‚°
í•œ ë²ˆì˜ ê²€ìƒ‰ + ì‘ë‹µ ìƒì„± ì‹œ ë°œìƒí•˜ëŠ” ë¹„ìš© ë¶„ì„
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent))

from src.korean_vector_store import KoreanVectorStore
from src.hybrid_search import HybridSearch
import google.generativeai as genai
import os
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()


def calculate_embedding_cost():
    """ì„ë² ë”© ë¹„ìš© ê³„ì‚° (ko-sroberta-multitask ì‚¬ìš©)"""
    print("\nğŸ“Š ì„ë² ë”© ë¹„ìš© ë¶„ì„")
    print("-" * 50)
    
    # ko-sroberta-multitaskëŠ” ë¡œì»¬ ëª¨ë¸ì´ë¯€ë¡œ ë¹„ìš© ì—†ìŒ
    print("âœ… ì„ë² ë”© ëª¨ë¸: ko-sroberta-multitask (ë¡œì»¬)")
    print("ğŸ’° ë¹„ìš©: $0 (ë¬´ë£Œ - ë¡œì»¬ ì‹¤í–‰)")
    
    return 0


def calculate_search_cost():
    """ë²¡í„° ê²€ìƒ‰ ë¹„ìš© ê³„ì‚°"""
    print("\nğŸ” ë²¡í„° ê²€ìƒ‰ ë¹„ìš© ë¶„ì„")
    print("-" * 50)
    
    # ChromaDBëŠ” ë¡œì»¬ ë²¡í„° DBì´ë¯€ë¡œ ë¹„ìš© ì—†ìŒ
    print("âœ… ë²¡í„° DB: ChromaDB (ë¡œì»¬)")
    print("ğŸ’° ë¹„ìš©: $0 (ë¬´ë£Œ - ë¡œì»¬ ì‹¤í–‰)")
    
    return 0


def calculate_llm_cost(query: str = "ì¸ê¶Œ êµìœ¡ì„ ëª‡í”„ë¡œê°€ ë°›ì•˜ì–´?"):
    """LLM ì‘ë‹µ ìƒì„± ë¹„ìš© ê³„ì‚°"""
    print("\nğŸ¤– LLM ë¹„ìš© ë¶„ì„ (Google Gemini)")
    print("-" * 50)
    
    # ë²¡í„° ìŠ¤í† ì–´ì—ì„œ ì‹¤ì œ ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
    vector_store = KoreanVectorStore(persist_directory="data/chroma_db")
    results = vector_store.similarity_search(query, k=5)
    
    # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    context_texts = []
    for doc in results:
        context_texts.append(doc.page_content)
    
    full_context = "\n\n".join(context_texts)
    
    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    system_prompt = """ë‹¹ì‹ ì€ ì‚¼ì„±ì „ìì˜ ESG ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
    ì œê³µëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
    ë‹µë³€ì€ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì‘ì„±í•˜ë˜, ì¤‘ìš”í•œ ì„¸ë¶€ì‚¬í•­ì€ í¬í•¨í•˜ì„¸ìš”."""
    
    user_prompt = f"""ë‹¤ìŒ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”:

<ì»¨í…ìŠ¤íŠ¸>
{full_context}
</ì»¨í…ìŠ¤íŠ¸>

ì§ˆë¬¸: {query}

ë‹µë³€:"""
    
    # ì „ì²´ í”„ë¡¬í”„íŠ¸
    full_prompt = system_prompt + "\n\n" + user_prompt
    
    # í† í° ìˆ˜ ê³„ì‚° (ê·¼ì‚¬ì¹˜)
    # GeminiëŠ” ë¬¸ì ìˆ˜ ê¸°ë°˜ìœ¼ë¡œ ëŒ€ëµ ê³„ì‚°
    input_chars = len(full_prompt)
    avg_output_chars = 500  # í‰ê·  ì‘ë‹µ ê¸¸ì´
    
    # Gemini 2.0 Flash ê°€ê²© (2024ë…„ ê¸°ì¤€)
    # Input: $0.075 per 1M characters
    # Output: $0.30 per 1M characters
    
    input_cost = (input_chars / 1_000_000) * 0.075
    output_cost = (avg_output_chars / 1_000_000) * 0.30
    
    print(f"ğŸ“ ì¿¼ë¦¬: {query}")
    print(f"ğŸ“„ ì»¨í…ìŠ¤íŠ¸ í¬ê¸°: {len(full_context):,} ë¬¸ì")
    print(f"ğŸ“¥ ì…ë ¥ í”„ë¡¬í”„íŠ¸ í¬ê¸°: {input_chars:,} ë¬¸ì")
    print(f"ğŸ“¤ ì˜ˆìƒ ì¶œë ¥ í¬ê¸°: {avg_output_chars:,} ë¬¸ì")
    print(f"\nğŸ’µ Gemini 2.0 Flash ê°€ê²©:")
    print(f"   - ì…ë ¥: $0.075 / 1M ë¬¸ì")
    print(f"   - ì¶œë ¥: $0.30 / 1M ë¬¸ì")
    print(f"\nğŸ’° ì˜ˆìƒ ë¹„ìš©:")
    print(f"   - ì…ë ¥ ë¹„ìš©: ${input_cost:.6f}")
    print(f"   - ì¶œë ¥ ë¹„ìš©: ${output_cost:.6f}")
    print(f"   - ì´ LLM ë¹„ìš©: ${input_cost + output_cost:.6f}")
    
    # ì‹¤ì œ API í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜
    print(f"\nğŸ”„ ì‹¤ì œ API í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜...")
    
    # API ì„¤ì •
    genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
    model = genai.GenerativeModel('gemini-2.0-flash-exp')
    
    try:
        # ì‹¤ì œ ì‘ë‹µ ìƒì„±
        response = model.generate_content(full_prompt)
        actual_output_chars = len(response.text)
        actual_output_cost = (actual_output_chars / 1_000_000) * 0.30
        
        print(f"âœ… ì‹¤ì œ ì‘ë‹µ í¬ê¸°: {actual_output_chars:,} ë¬¸ì")
        print(f"ğŸ’° ì‹¤ì œ ì¶œë ¥ ë¹„ìš©: ${actual_output_cost:.6f}")
        print(f"ğŸ’° ì‹¤ì œ ì´ ë¹„ìš©: ${input_cost + actual_output_cost:.6f}")
        
        return input_cost + actual_output_cost
        
    except Exception as e:
        print(f"âš ï¸ API í˜¸ì¶œ ì‹¤íŒ¨ (ì˜ˆìƒ ë¹„ìš©ë§Œ í‘œì‹œ): {e}")
        return input_cost + output_cost


def calculate_total_cost_per_query():
    """ì¿¼ë¦¬ë‹¹ ì´ ë¹„ìš© ê³„ì‚°"""
    print("\n" + "=" * 60)
    print("ğŸ’° RAG ì‹œìŠ¤í…œ ì¿¼ë¦¬ë‹¹ ì´ ë¹„ìš© ë¶„ì„")
    print("=" * 60)
    
    # ê° êµ¬ì„± ìš”ì†Œ ë¹„ìš©
    embedding_cost = calculate_embedding_cost()
    search_cost = calculate_search_cost()
    llm_cost = calculate_llm_cost()
    
    total_cost = embedding_cost + search_cost + llm_cost
    
    print("\n" + "=" * 60)
    print("ğŸ“Š ë¹„ìš© ìš”ì•½")
    print("=" * 60)
    print(f"1. ì„ë² ë”© ë¹„ìš©: ${embedding_cost:.6f}")
    print(f"2. ê²€ìƒ‰ ë¹„ìš©: ${search_cost:.6f}")
    print(f"3. LLM ë¹„ìš©: ${llm_cost:.6f}")
    print(f"\nğŸ¯ ì¿¼ë¦¬ë‹¹ ì´ ë¹„ìš©: ${total_cost:.6f}")
    
    # ì›”ê°„ ì˜ˆìƒ ë¹„ìš©
    queries_per_day = 100
    queries_per_month = queries_per_day * 30
    monthly_cost = total_cost * queries_per_month
    
    print(f"\nğŸ“… ì›”ê°„ ì˜ˆìƒ ë¹„ìš© (ì¼ {queries_per_day}íšŒ ì‚¬ìš© ê¸°ì¤€):")
    print(f"   - ì›” {queries_per_month:,}íšŒ ì¿¼ë¦¬")
    print(f"   - ì›” ì˜ˆìƒ ë¹„ìš©: ${monthly_cost:.2f}")
    
    # ë¹„ìš© ì ˆê° ë°©ì•ˆ
    print(f"\nğŸ’¡ ë¹„ìš© ì ˆê° ë°©ì•ˆ:")
    print("1. âœ… ë¡œì»¬ ì„ë² ë”© ëª¨ë¸ ì‚¬ìš© (í˜„ì¬ ì ìš©)")
    print("2. âœ… ë¡œì»¬ ë²¡í„° DB ì‚¬ìš© (í˜„ì¬ ì ìš©)")
    print("3. ğŸ“Œ Gemini Flash ëª¨ë¸ ì‚¬ìš© (í˜„ì¬ ì ìš© - ê°€ì¥ ì €ë ´í•œ ì˜µì…˜)")
    print("4. ğŸ’¾ ì‘ë‹µ ìºì‹±ìœ¼ë¡œ ì¤‘ë³µ ì¿¼ë¦¬ ë¹„ìš© ì ˆê° ê°€ëŠ¥")
    print("5. ğŸ“ ì»¨í…ìŠ¤íŠ¸ í¬ê¸° ìµœì í™” (k=5 â†’ k=3ìœ¼ë¡œ ì¶•ì†Œ ê°€ëŠ¥)")
    
    return total_cost


def compare_with_other_models():
    """ë‹¤ë¥¸ LLM ëª¨ë¸ê³¼ ë¹„ìš© ë¹„êµ"""
    print("\n" + "=" * 60)
    print("ğŸ”„ ë‹¤ë¥¸ LLM ëª¨ë¸ê³¼ ë¹„ìš© ë¹„êµ")
    print("=" * 60)
    
    # í‰ê·  ì…ë ¥/ì¶œë ¥ í¬ê¸° (ë¬¸ì)
    avg_input = 5000
    avg_output = 500
    
    models = [
        {
            "name": "Gemini 2.0 Flash (í˜„ì¬)",
            "input_price": 0.075 / 1_000_000,
            "output_price": 0.30 / 1_000_000,
            "unit": "ë¬¸ì"
        },
        {
            "name": "GPT-4o mini",
            "input_price": 0.15 / 1_000_000,  # per token, ~4 chars per token
            "output_price": 0.60 / 1_000_000,
            "unit": "í† í°",
            "char_per_token": 4
        },
        {
            "name": "Claude 3 Haiku",
            "input_price": 0.25 / 1_000_000,
            "output_price": 1.25 / 1_000_000,
            "unit": "í† í°",
            "char_per_token": 4
        },
        {
            "name": "GPT-3.5 Turbo",
            "input_price": 0.50 / 1_000_000,
            "output_price": 1.50 / 1_000_000,
            "unit": "í† í°",
            "char_per_token": 4
        }
    ]
    
    print(f"ğŸ“Š ê¸°ì¤€: ì…ë ¥ {avg_input:,}ì, ì¶œë ¥ {avg_output:,}ì\n")
    
    for model in models:
        if model["unit"] == "í† í°":
            # í† í° ê¸°ë°˜ ëª¨ë¸ì€ ë¬¸ìë¥¼ í† í°ìœ¼ë¡œ ë³€í™˜
            input_tokens = avg_input / model["char_per_token"]
            output_tokens = avg_output / model["char_per_token"]
            input_cost = input_tokens * model["input_price"]
            output_cost = output_tokens * model["output_price"]
        else:
            # ë¬¸ì ê¸°ë°˜ ëª¨ë¸
            input_cost = avg_input * model["input_price"]
            output_cost = avg_output * model["output_price"]
        
        total = input_cost + output_cost
        
        print(f"ğŸ¤– {model['name']}:")
        print(f"   ì…ë ¥: ${input_cost:.6f}")
        print(f"   ì¶œë ¥: ${output_cost:.6f}")
        print(f"   ì´ì•¡: ${total:.6f}")
        
        if model['name'] == "Gemini 2.0 Flash (í˜„ì¬)":
            print(f"   âœ… í˜„ì¬ ì„ íƒëœ ëª¨ë¸")
        print()


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("\nğŸš€ RAG ì‹œìŠ¤í…œ ë¹„ìš© ë¶„ì„ ì‹œì‘\n")
    
    # 1. ì¿¼ë¦¬ë‹¹ ì´ ë¹„ìš© ê³„ì‚°
    cost_per_query = calculate_total_cost_per_query()
    
    # 2. ë‹¤ë¥¸ ëª¨ë¸ê³¼ ë¹„êµ
    compare_with_other_models()
    
    print("\nâœ… ë¹„ìš© ë¶„ì„ ì™„ë£Œ!\n")
    
    # ìµœì¢… ìš”ì•½
    print("ğŸ“Œ í•µì‹¬ ìš”ì•½:")
    print(f"- ì¿¼ë¦¬ë‹¹ ë¹„ìš©: ${cost_per_query:.6f} (ì•½ {cost_per_query * 1400:.2f}ì›)")
    print(f"- ì£¼ìš” ë¹„ìš©: LLM API í˜¸ì¶œ (Gemini 2.0 Flash)")
    print(f"- ì ˆê° ìš”ì†Œ: ë¡œì»¬ ì„ë² ë”© + ë¡œì»¬ ë²¡í„° DB ì‚¬ìš©")
    print(f"- ì¶”ì²œ: í˜„ì¬ êµ¬ì„±ì´ ê°€ì¥ ë¹„ìš© íš¨ìœ¨ì ")


if __name__ == "__main__":
    main()